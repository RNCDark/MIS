{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modeling\n",
    "In addition to dimensionality concerns, there were other health factors for input data that we've discussed previously.  Sklearn comes with tools to help us normalize our data, encode categorical data, detect outliers, and much more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "Due to the way floating point numbers work on digital systems, the closer they are to zero the more accurate they are.  If you have an extremely large value, whole integers begin to get skipped, before that happens decimal precision is lost.  Due to this we can improve the performance of many estimators by scaling the data first, some estimators aren't sensitive to unscaled data but in general we can say that models prefer standardized gaussian distribution for input features. Another problem that can exist in raw data is that the scale of two different featues can confuse estimators (imagine distance in miles vs inches), an estimator could place more significance on the larger value.\n",
    "\n",
    "There is a hidden danger we could be introducing here known as data leakage, we will discuss what this is and how to prevent it another day.\n",
    "\n",
    "* StandardScaler - 0 mean and unit variance\n",
    "* MinMaxScaler - scale values to a specific range, lets you preserve values of 0\n",
    "* RobustScaler - scaling is not linear, good if you have many outliers\n",
    "* PowerTransformer - good at non linear transformations (similar to log)\n",
    "* QuantileTransformer - a non linear transformer that even works on bimodal or uniform distributions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.37690335] [-0.28124444]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(n_samples=100, n_features=1, noise=100, random_state=100)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "# call inverse_transform to undo the effect of the transformer\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "print(X[0], X_scaled[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Engineering\n",
    "We typically only transform the input features, however it might be necessary if the model is not fitting well. Log transform is often used for this, don't forget to apply the inverse when avaluating predications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Encoding\n",
    "As we've discussed before, input data must be quantitative, if your data set has many categorical features this could be very limiting.  If you have categorical labels they must be converted to quantitative before they can be used to train a model, for example converting hair color from 'brown' to an RGB value.  Another example would be to convert ordinal data to discrete dummy codes (freshman = 1, sophmore = 2, junior = 3), even though these values are categorical there is a specific ordering to them so we might be able to use them.  This could be done manually or with sklearn's OrdinalEncoder.  If there is no suitable conversion these values can still be used they will just need to be converted first.  Which method to do this will depend on the model and the data, so try an approach and see how it affects the problem.\n",
    "\n",
    "###  One Hot\n",
    "One hot encoding transforms a feature with k possible values into k new binary features (0 or 1).  Care must be taken however, if the converted feature has a large number of possible values this could greatly increase the complexity of the model.  If this is the case labels can be combined (light brown, brown, and chestnut being combined), or a different approach can be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>is_action</th>\n",
       "      <th>is_puzzle</th>\n",
       "      <th>is_rpg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>action</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>puzzle</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>puzzle</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cat  is_action  is_puzzle  is_rpg\n",
       "0  action          1          0       0\n",
       "1     rpg          0          0       1\n",
       "2     rpg          0          0       1\n",
       "3     rpg          0          0       1\n",
       "4  puzzle          0          1       0\n",
       "5  puzzle          0          1       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "enc = LabelBinarizer()\n",
    "vals = ['action', 'rpg', 'rpg', 'rpg', 'puzzle', 'puzzle']\n",
    "df = pd.DataFrame(vals, columns=['cat'])\n",
    "\n",
    "# convert to dummy codes and one hot array\n",
    "one_hot = enc.fit_transform(df)\n",
    "\n",
    "# combine for nice output\n",
    "df = pd.concat([df, pd.DataFrame(one_hot, columns=['is_action', 'is_puzzle', 'is_rpg'])], axis=1)\n",
    "df\n",
    "\n",
    "df['one_hot_1'] = one_hot[:, 0]\n",
    "df['one_hot_2'] = one_hot[:, 1]\n",
    "df['one_hot_3'] = one_hot[:, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Encoding\n",
    "This type of encoding takes the frequency of a label occuring and uses that as quantitative value, sometimes this value will have some relation to the output feature.  There is no built in method to do this, but it can be easily achieved with pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>action</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rpg</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rpg</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rpg</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>puzzle</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>puzzle</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cat      freq\n",
       "0  action  0.166667\n",
       "1     rpg  0.500000\n",
       "2     rpg  0.500000\n",
       "3     rpg  0.500000\n",
       "4  puzzle  0.333333\n",
       "5  puzzle  0.333333"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(vals, columns=['cat'])\n",
    "\n",
    "# get frequency of each label\n",
    "fe = df.groupby('cat').size() / len(df)\n",
    "\n",
    "# map labels to frequency\n",
    "df['freq'] = df['cat'].map(fe)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Hashing\n",
    "Feature hashing is a technique similar to one hot encoding, however instead of assinging each unique value its own feature, each value is hashed by a user specified number of buckets.  Due to this the number of features generated can be directly controlled by the user.  The return from this operation is a sparse array so you will need to do some data modeling to get it back into your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    action\n",
      "1       rpg\n",
      "2       rpg\n",
      "3       rpg\n",
      "4    puzzle\n",
      "5    puzzle\n",
      "Name: cat, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>action</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rpg</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rpg</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rpg</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>puzzle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>puzzle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cat    0    1\n",
       "0  action  0.0 -2.0\n",
       "1     rpg -2.0  1.0\n",
       "2     rpg -2.0  1.0\n",
       "3     rpg -2.0  1.0\n",
       "4  puzzle  1.0 -1.0\n",
       "5  puzzle  1.0 -1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import FeatureHasher\n",
    "import pandas as pd\n",
    "\n",
    "# n_featuers is how many buckets (features) your hash should use\n",
    "fh = FeatureHasher(n_features=2, input_type='string')\n",
    "df = pd.DataFrame(vals, columns=['cat'])\n",
    "\n",
    "print(df.cat)\n",
    "\n",
    "# the toarray converts from a sparse matrix to dense which we can create a df with\n",
    "res = fh.fit_transform(df.cat)\n",
    "fh_df = pd.DataFrame(res.toarray())\n",
    "\n",
    "df = pd.concat([df, fh_df], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "There are two different types of actions we can take when dealing with outliers.  Novelty detection is when you already have a clean dataset and you are trying to determine if new data is an inlier or an outlier.  Outlier detection is when you have a potentially dirty dataset and you are trying to determine if any of the data is deviant.  Outliers generally take one of the following forms.\n",
    "\n",
    "* global - incredibly rare event (it snowed in Florida)\n",
    "* contextual - abnormal due to time (hurricane in Florida during winter)\n",
    "* collective - abnormal due to amount (five hurricanes hitting Orlando on the same day during late summer)\n",
    "\n",
    "Something to keep in mind with outliers is that they are not necessarily bad, in fact they might be the most important samples in your data set.  If you detect outliers you will need to examine them and understand their relevance to the problem you are trying to solve.  Its possible I could have a 7' tall student in my class, I wouldn't necessarily want my model to consider that sample.  Its possible I could get a student that gets a 100 on every test / assignment, I would probably want my model to try and detect this.\n",
    "\n",
    "### Local Outlier Factor\n",
    "Many applications of machine learning will require outliers to be removed in order to get good predictions, this is one reason we look at the distribution of our features during EDA.  However, when we do this we are only looking at single feature at a time (univariate).  For example lets say its not uncommon for somebody to be 6', its also common for somebody else to weigh 120 lbs, however it would be very uncommon for somebody to have both of those traits.  Local Outlier Factor uses an algorithm that computes the density of data with respect to all features (multivariate) to determine if a sample is an inlier or an outlier.  Something to keep in mind is that when we call fit the argument name is still 'X', however we might pass in the output as well, or only parts of the input, the y argument is ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg rating</th>\n",
       "      <th>geek rating</th>\n",
       "      <th>num votes</th>\n",
       "      <th>year</th>\n",
       "      <th>outlier</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.32</td>\n",
       "      <td>8.200</td>\n",
       "      <td>21003</td>\n",
       "      <td>2005</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.72</td>\n",
       "      <td>8.153</td>\n",
       "      <td>3646</td>\n",
       "      <td>2015</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.27</td>\n",
       "      <td>8.134</td>\n",
       "      <td>15846</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.25</td>\n",
       "      <td>8.055</td>\n",
       "      <td>10507</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.20</td>\n",
       "      <td>8.049</td>\n",
       "      <td>13715</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.13</td>\n",
       "      <td>8.037</td>\n",
       "      <td>41009</td>\n",
       "      <td>2002</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.10</td>\n",
       "      <td>8.022</td>\n",
       "      <td>40962</td>\n",
       "      <td>2007</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      avg rating  geek rating  num votes  year  outlier\n",
       "rank                                                   \n",
       "1           8.32        8.200      21003  2005       -1\n",
       "2           8.72        8.153       3646  2015       -1\n",
       "3           8.27        8.134      15846  2012        1\n",
       "4           8.25        8.055      10507  2013        1\n",
       "5           8.20        8.049      13715  2006        1\n",
       "6           8.13        8.037      41009  2002       -1\n",
       "7           8.10        8.022      40962  2007       -1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('assets\\small_data.csv', index_col='rank')\n",
    "df = df.drop('names', axis=1)\n",
    "\n",
    "clf = LocalOutlierFactor(n_neighbors=5)\n",
    "df['outlier'] = clf.fit_predict(df)\n",
    "\n",
    "df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow\n",
    "There is not a strict blueprint for how to complete a machine learning problem, with varying data the workflow for each problem will be drastically different.  This general workflow can help, but shouldn't be strictly followed.  As the course progresses we will uncover more and transition from naive approaches to more robust.\n",
    "\n",
    "<td> <img src=\"images\\ml_workflow01.png\" alt=\"Drawing\" style=\"width:850px;\"/> </td>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OK\n",
    "One of the most important skills for an engineer working in this field is the ability to process data.  Often when working with models the best way to get better performance isn't to manipulate the model, its too manipulate the data.  Which specific thing to try will depend on the model and data, through the course we will explore ways to tell which technique we should apply to the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
